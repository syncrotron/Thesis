{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Developed by Samuel Horovatin at the University of Saskatchewan\n",
    "# July, 2021\n",
    "from plantcv import plantcv as pcv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "from skimage.io import imshow\n",
    "from sklearn.cluster import KMeans"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Base paramaters used by plantcv for image discovery and processing\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 8]\n",
    "class options:\n",
    "    def __init__(self):\n",
    "        # Input image path/filename\n",
    "        self.datastore_base_dir = \"/datastore/AGILE/BELToutput/LDP_Sebastian\"\n",
    "        self.extention_pattern = \".jpg\"\n",
    "        # Debug mode = None, \"plot\", or \"print\"\n",
    "        self.debug = None #DO NOT SET TO PLOT FOR BIG DATA RUNS.\n",
    "        # Store output images (True/False)\n",
    "        self.writeimg = False\n",
    "        # Results path/filename\n",
    "        self.result = \"results.txt\"\n",
    "        # Image output directory path\n",
    "        self.outdir = \"/birl2/users/sch923/Thesis/Lentil/output\"\n",
    "\n",
    "# Initialize options\n",
    "args = options()\n",
    "# Set PlantCV debug mode to input debug method\n",
    "pcv.params.debug = args.debug\n",
    "# Increase text size in plots\n",
    "pcv.params.text_size = 20\n",
    "pcv.params.text_thickness = 10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Searches for all files with certain pattern in datastore_base_dir\n",
    "\n",
    "files = []\n",
    "for dirpath, dirnames, filenames in os.walk(args.datastore_base_dir):\n",
    "    for filename in [f for f in filenames if f.endswith(args.extention_pattern)]:\n",
    "        files.append(os.path.join(dirpath, filename))\n",
    "\n",
    "print(f\"=== Found ({len(files)}) files of pattern {args.extention_pattern} ===\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for lentil_image in os.listdir(args.test_dir):\n",
    "#     if lentil_image[len(lentil_image)-3:] != 'png':\n",
    "#         continue\n",
    "#     img, path, filename = pcv.readimage(filename=args.test_dir+lentil_image)\n",
    "#     img = pcv.white_balance(img) #Good to normalize the \n",
    "#     cs_plot = pcv.visualize.colorspaces(rgb_img=img, original_img=False)\n",
    "#     s = pcv.rgb2gray_hsv(rgb_img=img, channel='s')\n",
    "#     s_thresh = pcv.threshold.binary(gray_img=s, threshold=60, max_value=255, object_type='light') # threshold is 60 to remove little lentil flecks\n",
    "#     b = pcv.rgb2gray_lab(rgb_img=img, channel='b')\n",
    "#     b_thresh = pcv.threshold.binary(gray_img=b, threshold=137, max_value=255, object_type='light')\n",
    "#     a = pcv.rgb2gray_lab(rgb_img=img, channel='a')\n",
    "#     a_thresh = pcv.threshold.binary(gray_img=a, threshold=133, max_value=255, object_type='light')\n",
    "#     bs = pcv.logical_or(bin_img1=s_thresh, bin_img2=b_thresh)\n",
    "#     bsa = pcv.logical_or(bin_img1=bs, bin_img2=a_thresh)\n",
    "#     bsa_fill1 = pcv.fill(bin_img=bsa, size=200) # Fill small noise\n",
    "#     bsa_fill2 = pcv.dilate(gray_img=bsa_fill1, ksize=6, i=2)\n",
    "#     # bsa_fill3 and bsa_fill4 are to get rid of tiny lentil flakes\n",
    "#     bsa_fill3 = pcv.erode(bsa_fill2, ksize=12, i=6)\n",
    "#     bsa_fill4 = pcv.dilate(gray_img=bsa_fill3, ksize=20, i=6) # If no lentil is present, can cause errors\n",
    "#     # Coppied this check from \"fill_holes\" source: catches empty images caused by erode and dilate.\n",
    "#     if len(np.shape(bsa_fill4)) != 2 or len(np.unique(bsa_fill4)) != 2:\n",
    "#         continue\n",
    "#     filled_mask1 = pcv.fill_holes(bsa_fill4)\n",
    "\n",
    "#     id_objects, obj_hierarchy = pcv.find_objects(img=img, mask=filled_mask1)\n",
    "#     roi_contour, roi_hierarchy = pcv.roi.rectangle(img, 0, 0, -400, -400)\n",
    "#     roi_objects, roi_obj_hierarchy, kept_mask, obj_area = pcv.roi_objects(img, 'partial', roi_contour, roi_hierarchy, id_objects, obj_hierarchy)\n",
    "#     clusters_i, contours, hierarchies = pcv.cluster_contours(img1, roi_objects, roi_obj_hierarchy, 4, 6)\n",
    "#     # obj, mask = pcv.object_composition(img=img, contours=id_objects, hierarchy=obj_hierarchy)\n",
    "#     # crop_img = pcv.auto_crop(img=img, obj=obj, padding_x=0, padding_y=0)\n",
    "#     # pcv.print_image(crop_img, args.outdir+\"cropped_\"+lentil_image)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Bulk proccesses all found images, flattens them, and loads them int array for training\n",
    "\n",
    "IMG_X = 200\n",
    "IMG_Y = 200\n",
    "IMG_Z = 3\n",
    "FILE_LIMITER = 1000 # Only used for manual testing in for loop\n",
    "i = 0\n",
    "\n",
    "lentil_images=[]\n",
    "lentil_images_names=[]\n",
    "\n",
    "for lentil_img_path in random.sample(files, FILE_LIMITER):\n",
    "    try:\n",
    "        img, lentil_img_path, filename = pcv.readimage(filename=lentil_img_path)\n",
    "    except:\n",
    "        print(f\"Error opening file: {lentil_img_path}\")\n",
    "        continue\n",
    "    \n",
    "    wbalance_img = pcv.white_balance(img) #Good to normalize the white balance\n",
    "    gray_img = pcv.rgb2gray(wbalance_img)\n",
    "    img_resized=resize(gray_img,(IMG_X, IMG_Y, IMG_Z))\n",
    "    \n",
    "    \n",
    "    lentil_images.append(img_resized.flatten())\n",
    "    lentil_images_names.append(os.path.join(lentil_img_path, filename))\n",
    "\n",
    "print(f\"Loaded ({len(lentil_images)}) image files\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Trains n number of k-mean models, with increment of n = k of the model\n",
    "\n",
    "kMax = min(10, len(lentil_images))\n",
    "kMin = 2 # Having K = 1 is a waste of time\n",
    "lentil_kmean_models = []\n",
    "wcss = [] # For 'within cluster sum of squares' calcuation, which is used to guage correct K value.\n",
    "\n",
    "# Fits KMean to data using multiple values for K\n",
    "for k in range(kMin, kMax):\n",
    "    print(f\"========= Training k={k}... =========\")\n",
    "    model = KMeans(n_clusters=k, random_state=0)\n",
    "    model.fit(lentil_images)\n",
    "    wcss.append(model.inertia_)\n",
    "    lentil_kmean_models.append(model)\n",
    "\n",
    "print(f\"========= Training Complete! K-Means Models Trained = {kMax-kMin}... =========\")    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Trains t-SNE models\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "k = kMin\n",
    "prediction_df = pd.DataFrame(columns=['img', 'k', 'group_pred']) \n",
    "\n",
    "for model in lentil_kmean_models:\n",
    "    model_pred = model.predict(lentil_images)\n",
    "    for name, pred in zip(lentil_images_names, model_pred):\n",
    "        prediction_df = prediction_df.append({'img': name, 'k': k, 'group_pred': pred }, ignore_index=True)\n",
    "    k = k + 1\n",
    "\n",
    "prediction_df.to_csv(\"pattern_10000.csv\", encoding='utf-8', sep=',', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Produces wcss graph for evaluation of appropriate value of K\n",
    "# https://towardsdatascience.com/machine-learning-algorithms-part-9-k-means-example-in-python-f2ad05ed5203\n",
    "\n",
    "plt.plot(range(kMin, kMax), wcss)\n",
    "plt.title('Elbow Method For Optimum K Clusters')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS (Within Cluster Sum Of Squares)')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c0aca8d92906243bc5f472e115d4e30ce6a6cc244b7756682cd7af636cdaa35"
  },
  "kernelspec": {
   "display_name": "Python (thesis_env)",
   "language": "python",
   "name": "thesis_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
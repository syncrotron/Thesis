{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2261274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Logger Imports\n",
    "import time\n",
    "import logging\n",
    "import sys\n",
    "from logging.handlers import TimedRotatingFileHandler\n",
    "\n",
    "# Model Specific Imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Visulaization and metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import fbeta_score\n",
    "import dataframe_image as dfi\n",
    "from sklearn.metrics import roc_curve, auc, RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "528ae041",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FORMATTER = logging.Formatter(\"%(asctime)s —  %(levelname)s — %(message)s\")\n",
    "LOG_FILE = \"LR.log\"\n",
    "\n",
    "def get_console_handler():\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setFormatter(FORMATTER)\n",
    "    return console_handler\n",
    "\n",
    "def get_file_handler():\n",
    "    file_handler = TimedRotatingFileHandler(LOG_FILE, when='midnight')\n",
    "    file_handler.setFormatter(FORMATTER)\n",
    "    return file_handler\n",
    "\n",
    "def get_logger(logger_name):\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    \n",
    "    if (logger.hasHandlers()): # important as removes duplicate loggers (and thus duplicate log entries)\n",
    "        logger.handlers.clear()\n",
    "    logger.setLevel(logging.DEBUG) # better to have too much log than not enough\n",
    "    logger.addHandler(get_console_handler())\n",
    "    logger.addHandler(get_file_handler())\n",
    "    # with this pattern, it's rarely necessary to propagate the error up to parent\n",
    "    logger.propagate = False\n",
    "    return logger\n",
    "\n",
    "logger = get_logger(\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44193e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Categories_Durum=['CFP-CK1','CFP-CK2'] # [Infected, Healthy]\n",
    "Categories_Bread=['CFP-CK3','CFP-CK4'] # [Infected, Healthy]\n",
    "Categories_Test=['CFP-B179','CFP-B223'] # 39/103 or 37.8% infected; 21/105 or 20% infected\n",
    "\n",
    "All_Categories = [Categories_Durum, Categories_Bread,Categories_Test]\n",
    "\n",
    "datadir='/student/sch923/Thesis/data/test_wheat_2021/Wheat/TestSamples' \n",
    "#path which contains all the categories of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-06-28 14:33:27,403 —  INFO — loading category: CFP-CK1\n",
      "2021-06-28 14:33:34,002 —  INFO — loaded category: CFP-CK1 successfully, found 43 images\n",
      "2021-06-28 14:33:34,004 —  INFO — loading category: CFP-CK2\n",
      "2021-06-28 14:33:41,216 —  INFO — loaded category: CFP-CK2 successfully, found 48 images\n",
      "2021-06-28 14:33:41,220 —  INFO — loading category: CFP-CK3\n",
      "2021-06-28 14:33:44,849 —  INFO — loaded category: CFP-CK3 successfully, found 24 images\n",
      "2021-06-28 14:33:44,851 —  INFO — loading category: CFP-CK4\n",
      "2021-06-28 14:33:49,524 —  INFO — loaded category: CFP-CK4 successfully, found 31 images\n",
      "2021-06-28 14:33:49,526 —  INFO — loading category: CFP-B179\n",
      "2021-06-28 14:34:05,067 —  INFO — loaded category: CFP-B179 successfully, found 103 images\n",
      "2021-06-28 14:34:05,069 —  INFO — loading category: CFP-B223\n",
      "2021-06-28 14:34:19,538 —  INFO — loaded category: CFP-B223 successfully, found 96 images\n"
     ]
    }
   ],
   "source": [
    "flat_arr, target_arr=[],[]\n",
    "\n",
    "# creating species specific data sets\n",
    "for Categories in All_Categories:\n",
    "    flat_arr.append(list())\n",
    "    target_arr.append(list())\n",
    "    for i in Categories:\n",
    "        logger.info(f'loading category: {i}')    \n",
    "        path=os.path.join(datadir,i) \n",
    "        image_count = 0\n",
    "        for img in os.listdir(path):  \n",
    "            img_array=imread(os.path.join(path,img))\n",
    "            img_resized=resize(img_array,(150,150,3))  \n",
    "            flat_arr[len(flat_arr)-1].append(img_resized.flatten())\n",
    "\n",
    "            if i in Categories_Test:\n",
    "                target_arr[len(flat_arr)-1].append(0) # As only % infection is known, all are assumed to be infected\n",
    "            else:\n",
    "                target_arr[len(flat_arr)-1].append(Categories.index(i))\n",
    "            image_count += 1\n",
    "        logger.info(f'loaded category: {i} successfully, found {image_count} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_arr_fun = lambda l : np.array(l)\n",
    "flat_data=list(map(list_arr_fun, flat_arr))\n",
    "target=list(map(list_arr_fun, target_arr))\n",
    "\n",
    "df_Durum=pd.DataFrame(flat_data[0])\n",
    "df_Bread=pd.DataFrame(flat_data[1])\n",
    "df_Complete=pd.DataFrame(np.append(flat_data[0], flat_data[1], axis=0))\n",
    "df_Test=pd.DataFrame(flat_data[2])\n",
    "\n",
    "df_Durum['Target']=target[0]\n",
    "df_Bread['Target']=target[1]\n",
    "df_Complete['Target']=np.append(target[0], target[1], axis=0)\n",
    "df_Test['Target']=target[2]\n",
    "\n",
    "x_Durum=df_Durum.iloc[:,:-1] #input data \n",
    "y_Durum=df_Durum.iloc[:,-1] #output data\n",
    "\n",
    "x_Bread=df_Bread.iloc[:,:-1] #input data \n",
    "y_Bread=df_Bread.iloc[:,-1] #output data\n",
    "\n",
    "x_Complete=df_Complete.iloc[:,:-1] #input data \n",
    "y_Complete=df_Complete.iloc[:,-1] #output data\n",
    "\n",
    "x_Test=df_Complete.iloc[:,:-1] #input data \n",
    "y_Test=df_Complete.iloc[:,-1] #output data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-06-28 14:34:19,822 —  INFO — ======= Start Of Data Split =======\n",
      "2021-06-28 14:34:19,867 —  INFO — Durum Splitted Successfully\n",
      "2021-06-28 14:34:19,883 —  INFO — Bread Splitted Successfully\n",
      "2021-06-28 14:34:19,913 —  INFO — Complete Splitted Successfully\n",
      "2021-06-28 14:34:19,942 —  INFO — Test Splitted Successfully\n",
      "2021-06-28 14:34:19,944 —  INFO — ======= End Of Data Split =======\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data Splitting\n",
    "logger.info('======= Start Of Data Split =======')\n",
    "x_train_Durum,x_test_Durum,y_train_Durum,y_test_Durum=train_test_split(x_Durum,y_Durum,test_size=0.20,random_state=77,stratify=y_Durum)\n",
    "logger.info('Durum Splitted Successfully')\n",
    "x_train_Bread,x_test_Bread,y_train_Bread,y_test_Bread=train_test_split(x_Bread,y_Bread,test_size=0.20,random_state=77,stratify=y_Bread)\n",
    "logger.info('Bread Splitted Successfully')\n",
    "x_train_Complete,x_test_Complete,y_train_Complete,y_test_Complete=train_test_split(x_Complete,y_Complete,test_size=0.20,random_state=77,stratify=y_Complete)\n",
    "logger.info('Complete Splitted Successfully')\n",
    "x_test_Test,_,y_test_Test,_=train_test_split(x_Test,y_Test,test_size=0.20,random_state=77,stratify=y_Test)\n",
    "logger.info('Test Splitted Successfully')\n",
    "logger.info('======= End Of Data Split =======\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelTrainer(model, x_train, y_train, model_name, method_name):\n",
    "    logger.info(f\"Starting to train {method_name} model...\")\n",
    "    start = time.time()\n",
    "    model.fit(x_train,y_train)\n",
    "    end = time.time()\n",
    "    logger.info(f\"The {model_name} model trained in: {str(end - start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-06-28 14:34:19,999 —  INFO — ======= Start Of Logistic Regression Model Generation =======\n",
      "2021-06-28 14:34:20,000 —  INFO — Starting to train LogR model...\n",
      "2021-06-28 14:34:47,731 —  INFO — The Durum model trained in: 27.73000144958496 seconds\n",
      "2021-06-28 14:34:47,738 —  INFO — Starting to train LogR model...\n",
      "2021-06-28 14:35:07,823 —  INFO — The Bread model trained in: 20.08215856552124 seconds\n",
      "2021-06-28 14:35:07,832 —  INFO — Starting to train LogR model...\n",
      "2021-06-28 14:35:48,158 —  INFO — The Complete model trained in: 40.324777364730835 seconds\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Models\n",
    "\n",
    "logger.info('======= Start Of Logistic Regression Model Generation =======')\n",
    "LogR_param_grid={'penalty':['l2'], 'C':[0.1,1,10,100], 'max_iter':[1024], 'solver': ['lbfgs'] } \n",
    "LogR_model_Durum=GridSearchCV(LogisticRegression(), LogR_param_grid, n_jobs=-1)\n",
    "LogR_model_Bread=GridSearchCV(LogisticRegression(), LogR_param_grid, n_jobs=-1)\n",
    "LogR_model_Complete=GridSearchCV(LogisticRegression(), LogR_param_grid, n_jobs=-1)\n",
    "\n",
    "modelTrainer(LogR_model_Durum, x_train_Durum, y_train_Durum, \"Durum\", \"LogR\")\n",
    "modelTrainer(LogR_model_Bread, x_train_Bread, y_train_Bread, \"Bread\", \"LogR\")\n",
    "modelTrainer(LogR_model_Complete, x_train_Complete, y_train_Complete, \"Complete\", \"LogR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-06-28 14:35:48,202 —  INFO — ======= Start Of SVM Model Generation =======\n",
      "2021-06-28 14:35:48,205 —  INFO — Starting to train SVM model...\n",
      "2021-06-28 14:36:04,542 —  INFO — The Durum model trained in: 16.33480405807495 seconds\n",
      "2021-06-28 14:36:04,556 —  INFO — Starting to train SVM model...\n",
      "2021-06-28 14:36:13,419 —  INFO — The Bread model trained in: 8.860675573348999 seconds\n",
      "2021-06-28 14:36:13,426 —  INFO — Starting to train SVM model...\n",
      "2021-06-28 14:36:48,003 —  INFO — The Complete model trained in: 34.57543182373047 seconds\n"
     ]
    }
   ],
   "source": [
    "# SVM Models\n",
    "\n",
    "logger.info('======= Start Of SVM Model Generation =======')\n",
    "SVM_param_grid={'C':[0.1,1,10,100],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf','poly']}\n",
    "svc=svm.SVC(probability=True)\n",
    "SVM_model_Durum=GridSearchCV(svm.SVC(probability=True), SVM_param_grid, n_jobs=-1)\n",
    "SVM_model_Bread=GridSearchCV(svm.SVC(probability=True), SVM_param_grid, n_jobs=-1)\n",
    "SVM_model_Complete=GridSearchCV(svm.SVC(probability=True), SVM_param_grid, n_jobs=-1)\n",
    "\n",
    "modelTrainer(SVM_model_Durum, x_train_Durum, y_train_Durum, \"Durum\", \"SVM\")\n",
    "modelTrainer(SVM_model_Bread, x_train_Bread, y_train_Bread, \"Bread\", \"SVM\")\n",
    "modelTrainer(SVM_model_Complete, x_train_Complete, y_train_Complete, \"Complete\", \"SVM\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-06-28 14:36:48,091 —  INFO — ======= Start Of K Nearest Neighbors Model Generation =======\n",
      "2021-06-28 14:36:48,093 —  INFO — Starting to train KNN model...\n",
      "2021-06-28 14:36:49,222 —  INFO — The Durum model trained in: 1.128831386566162 seconds\n",
      "2021-06-28 14:36:49,224 —  INFO — Starting to train KNN model...\n",
      "2021-06-28 14:36:50,403 —  INFO — The Bread model trained in: 1.1774656772613525 seconds\n",
      "2021-06-28 14:36:50,404 —  INFO — Starting to train KNN model...\n",
      "2021-06-28 14:36:51,586 —  INFO — The Complete model trained in: 1.180647611618042 seconds\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbors Models\n",
    "\n",
    "logger.info('======= Start Of K Nearest Neighbors Model Generation =======')\n",
    "KNN_param_grid={'n_neighbors':[5], 'weights':['uniform', 'distance']}\n",
    "KNN_model_Durum=GridSearchCV(KNeighborsClassifier(), KNN_param_grid, n_jobs=-1)\n",
    "KNN_model_Bread=GridSearchCV(KNeighborsClassifier(), KNN_param_grid, n_jobs=-1)\n",
    "KNN_model_Complete=GridSearchCV(KNeighborsClassifier(), KNN_param_grid, n_jobs=-1)\n",
    "\n",
    "modelTrainer(KNN_model_Durum, x_train_Durum, y_train_Durum, \"Durum\", \"KNN\")\n",
    "modelTrainer(KNN_model_Bread, x_train_Bread, y_train_Bread, \"Bread\", \"KNN\")\n",
    "modelTrainer(KNN_model_Complete, x_train_Complete, y_train_Complete, \"Complete\", \"KNN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-06-28 14:36:51,600 —  INFO — ======= Start Of Random Forest Model Generation =======\n",
      "2021-06-28 14:36:51,602 —  INFO — Starting to train RanF model...\n",
      "2021-06-28 14:36:53,356 —  INFO — The Durum model trained in: 1.7534055709838867 seconds\n",
      "2021-06-28 14:36:53,357 —  INFO — Starting to train RanF model...\n",
      "2021-06-28 14:36:54,949 —  INFO — The Bread model trained in: 1.5906870365142822 seconds\n",
      "2021-06-28 14:36:54,951 —  INFO — Starting to train RanF model...\n",
      "2021-06-28 14:36:57,106 —  INFO — The Complete model trained in: 2.153944730758667 seconds\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Models\n",
    "\n",
    "logger.info('======= Start Of Random Forest Model Generation =======')\n",
    "RanF_param_grid={'n_estimators':[100], 'criterion': ['gini', 'entropy']}\n",
    "RanF_model_Durum=GridSearchCV(RandomForestClassifier(), RanF_param_grid, n_jobs=-1)\n",
    "RanF_model_Bread=GridSearchCV(RandomForestClassifier(), RanF_param_grid, n_jobs=-1)\n",
    "RanF_model_Complete=GridSearchCV(RandomForestClassifier(), RanF_param_grid, n_jobs=-1)\n",
    "\n",
    "modelTrainer(RanF_model_Durum, x_train_Durum, y_train_Durum, \"Durum\", \"RanF\")\n",
    "modelTrainer(RanF_model_Bread, x_train_Bread, y_train_Bread, \"Bread\", \"RanF\")\n",
    "modelTrainer(RanF_model_Complete, x_train_Complete, y_train_Complete, \"Complete\", \"RanF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8e7f297d2aa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# For auc_roc curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTest_Set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mdisp_roc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRocCurveDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mdisp_roc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes_roc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "# Generation of confusion matrix for all models\n",
    "\n",
    "Classification_Label = ['Logistic Regression', 'Support Vector Machine', 'K Nearest Neighbors', 'Random Forest']\n",
    "Classification_Model = [ [LogR_model_Durum, LogR_model_Bread, LogR_model_Complete], [SVM_model_Durum, SVM_model_Bread, SVM_model_Complete], [KNN_model_Durum, KNN_model_Bread, KNN_model_Complete], [RanF_model_Durum, RanF_model_Bread, RanF_model_Complete]]\n",
    "Train_Labels = ['Durum', 'Bread', 'Complete']\n",
    "Test_Data_Sets = [(x_test_Durum, y_test_Durum), (x_test_Bread, y_test_Bread), (x_test_Complete, y_test_Complete), (x_test_Test, y_test_Test)]\n",
    "Data_Set_Label = ['Durum', 'Bread', 'Complete', 'Test']\n",
    "\n",
    "\n",
    "classification_model = []\n",
    "train_data_used = []\n",
    "test_data_used = []\n",
    "false_positive_rate = [] # fp / (fp + tn)\n",
    "false_negative_rate = [] # fn / (tp + fn)\n",
    "true_negative_rate = [] # tn / (tn + fp)\n",
    "negative_predictive_value = [] # tn / (tn + fn)\n",
    "false_discovery_rate = [] # fp / (tp + fp)\n",
    "true_positive_rate = [] # tp / (tp + fn)\n",
    "precision = [] # tp / (tp + fp)\n",
    "accuracy = [] # (tp + tn) / (tp + fp + fn + tn) \n",
    "f1_score = [] \n",
    "f2_score = []\n",
    "\n",
    "fig_conf, axes_conf = plt.subplots(nrows=7, ncols=7, figsize=(35,30))\n",
    "fig_roc, axes_roc = plt.subplots(nrows=7, ncols=7, figsize=(35,30))\n",
    "axes_conf = axes_conf.flatten()\n",
    "axes_roc = axes_roc.flatten()\n",
    "i=0\n",
    "\n",
    "for C_Label, C_Models in zip(Classification_Label, Classification_Model):\n",
    "    for Model, T_Label in zip(C_Models, Train_Labels):\n",
    "        for Test_Set, Test_Data_Label in zip(Test_Data_Sets, Data_Set_Label):\n",
    "            \n",
    "            y_test_pred = Model.predict(Test_Set[0])\n",
    "            \n",
    "            # For confusion matrix\n",
    "            cf_matrix = confusion_matrix(Test_Set[1], y_test_pred)\n",
    "            ncf_matrix = cf_matrix.astype('float') / cf_matrix.sum(axis=1)[:, np.newaxis]            \n",
    "            disp_conf = ConfusionMatrixDisplay(ncf_matrix ,display_labels=['infected', 'healthy'])\n",
    "            disp_conf.plot(ax=axes_conf[i], xticks_rotation=45)\n",
    "            disp_conf.im_.colorbar.remove()\n",
    "            axes_conf[i].title.set_text(f\"{C_Label} Confusion Matrix ({T_Label}\\n Model x {Test_Data_Label} Data)\")\n",
    "\n",
    "            # For metrics table\n",
    "            tn, fp, fn, tp = cf_matrix.ravel()\n",
    "            classification_model.append(C_Label)\n",
    "            train_data_used.append(T_Label)\n",
    "            test_data_used.append(Test_Data_Label)\n",
    "            false_positive_rate.append(fp / (fp + tn))\n",
    "            false_negative_rate.append(fn / (tp + fn)) \n",
    "            true_negative_rate.append(tn / (tn + fp)) \n",
    "            negative_predictive_value.append(tn / (tn + fn))\n",
    "            false_discovery_rate.append(fp / (tp + fp))\n",
    "            true_positive_rate.append(tp / (tp + fn))\n",
    "            precision.append(tp / (tp + fp)) \n",
    "            accuracy.append((tp + tn) / (tp + fp + fn + tn))\n",
    "            f1_score.append(fbeta_score(Test_Set[1], y_test_pred, beta=1))\n",
    "            f2_score.append(fbeta_score(Test_Set[1], y_test_pred, beta=2))\n",
    "\n",
    "            # For auc_roc curve\n",
    "            fpr, tpr, thresholds = roc_curve(Test_Set[1], y_test_pred)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            disp_roc = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)  \n",
    "            disp_roc.plot(ax=axes_roc[i])\n",
    "            axes_roc[i].title.set_text(f\"{C_Label} ROC Curve ({T_Label}\\n Model x {Test_Data_Label} Data)\")\n",
    "             \n",
    "            i = i + 1\n",
    "\n",
    "axes_conf[48].set_axis_off()\n",
    "fig_conf.tight_layout(pad=3.0)\n",
    "\n",
    "axes_roc[48].set_axis_off()\n",
    "fig_roc.tight_layout(pad=3.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate metrics table\n",
    "metrics_df = pd.DataFrame(list(zip(classification_model,train_data_used,test_data_used,false_positive_rate,false_negative_rate,true_negative_rate,negative_predictive_value,false_discovery_rate,true_positive_rate,precision,accuracy,f1_score,f2_score)),\n",
    "               columns =['Classifier', 'Training Data', 'Test Data', 'False Positive Rate', 'False Negative Rate', 'True Negative Rate', 'Negative Predictive Value', 'False Discovery Rate', 'True Positive Rate', 'Precision', 'Accuracy', 'F1 Score', 'F2 Score'])\n",
    "\n",
    "\n",
    "metrics_df.to_csv('metrics_df.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "eb2007956de45a70f93cb173489cef12649e77e7260e4b1744badcb2f800242b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
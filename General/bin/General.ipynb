{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Data Processing Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Logger Imports\n",
    "import time\n",
    "import logging\n",
    "import sys\n",
    "from logging.handlers import TimedRotatingFileHandler\n",
    "\n",
    "# Model Specific Imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Visulaization and metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import roc_curve, auc, RocCurveDisplay"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "FORMATTER = logging.Formatter(\"%(asctime)s —  %(levelname)s — %(message)s\")\n",
    "LOG_FILE = \"LR.log\"\n",
    "\n",
    "def get_console_handler():\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setFormatter(FORMATTER)\n",
    "    return console_handler\n",
    "\n",
    "def get_file_handler():\n",
    "    file_handler = TimedRotatingFileHandler(LOG_FILE, when='midnight')\n",
    "    file_handler.setFormatter(FORMATTER)\n",
    "    return file_handler\n",
    "\n",
    "def get_logger(logger_name):\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    \n",
    "    if (logger.hasHandlers()): # important as removes duplicate loggers (and thus duplicate log entries)\n",
    "        logger.handlers.clear()\n",
    "    logger.setLevel(logging.DEBUG) # better to have too much log than not enough\n",
    "    logger.addHandler(get_console_handler())\n",
    "    logger.addHandler(get_file_handler())\n",
    "    # with this pattern, it's rarely necessary to propagate the error up to parent\n",
    "    logger.propagate = False\n",
    "    return logger\n",
    "\n",
    "logger = get_logger(\"LR\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Categories_Durum=['CFP-CK1','CFP-CK2'] # [Infected, Healthy]\n",
    "Categories_Bread=['CFP-CK3','CFP-CK4'] # [Infected, Healthy]\n",
    "Categories_Test_B179 = ['CFP-B179-A','CFP-B179-B'] # [Infected, Healthy]\n",
    "Categories_Test_B223 = ['CFP-B223-A','CFP-B223-B'] # [Infected, Healthy]\n",
    "\n",
    "All_Categories = [Categories_Durum, Categories_Bread, Categories_Test_B179, Categories_Test_B223]\n",
    "\n",
    "datadir='/student/sch923/Thesis/data/test_wheat_2021/Wheat/TestSamples' \n",
    "#path which contains all the categories of images"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "flat_arr, target_arr=[],[]\n",
    "\n",
    "# creating species specific data sets\n",
    "for Categories in All_Categories:\n",
    "    flat_arr.append(list())\n",
    "    target_arr.append(list())\n",
    "    for i in Categories:\n",
    "        logger.info(f'loading category: {i}')    \n",
    "        path=os.path.join(datadir,i) \n",
    "        image_count = 0\n",
    "        for img in os.listdir(path):  \n",
    "            img_array=imread(os.path.join(path,img))\n",
    "            img_resized=resize(img_array,(150,150,3))  \n",
    "            flat_arr[len(flat_arr)-1].append(img_resized.flatten())\n",
    "            \n",
    "            target_arr[len(flat_arr)-1].append(Categories.index(i))\n",
    "            # if i in Categories_Test:\n",
    "            #     target_arr[len(flat_arr)-1].append(0) # As only % infection is known, all are assumed to be infected\n",
    "            # else:\n",
    "            #     target_arr[len(flat_arr)-1].append(Categories.index(i))\n",
    "            image_count += 1\n",
    "        logger.info(f'loaded category: {i} successfully, found {image_count} images')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list_arr_fun = lambda l : np.array(l)\n",
    "flat_data=list(map(list_arr_fun, flat_arr))\n",
    "target=list(map(list_arr_fun, target_arr))\n",
    "\n",
    "df_Durum=pd.DataFrame(flat_data[0])\n",
    "df_Bread=pd.DataFrame(flat_data[1])\n",
    "df_Complete=pd.DataFrame(np.append(flat_data[0], flat_data[1], axis=0))\n",
    "df_Test=pd.DataFrame(np.append(flat_data[2], flat_data[3], axis=0))\n",
    "\n",
    "df_Durum['Target']=target[0]\n",
    "df_Bread['Target']=target[1]\n",
    "df_Complete['Target']=np.append(target[0], target[1], axis=0)\n",
    "df_Test['Target']=np.append(target[2], target[3], axis=0)\n",
    "\n",
    "x_Durum=df_Durum.iloc[:,:-1] #input data \n",
    "y_Durum=df_Durum.iloc[:,-1] #output data\n",
    "\n",
    "x_Bread=df_Bread.iloc[:,:-1] #input data \n",
    "y_Bread=df_Bread.iloc[:,-1] #output data\n",
    "\n",
    "x_Complete=df_Complete.iloc[:,:-1] #input data \n",
    "y_Complete=df_Complete.iloc[:,-1] #output data\n",
    "\n",
    "x_Test=df_Complete.iloc[:,:-1] #input data \n",
    "y_Test=df_Complete.iloc[:,-1] #output data\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Data Splitting\n",
    "logger.info('======= Start Of Data Split =======')\n",
    "x_train_Durum,x_test_Durum,y_train_Durum,y_test_Durum=train_test_split(x_Durum,y_Durum,test_size=0.20,random_state=77,stratify=y_Durum)\n",
    "logger.info('Durum Splitted Successfully')\n",
    "x_train_Bread,x_test_Bread,y_train_Bread,y_test_Bread=train_test_split(x_Bread,y_Bread,test_size=0.20,random_state=77,stratify=y_Bread)\n",
    "logger.info('Bread Splitted Successfully')\n",
    "x_train_Complete,x_test_Complete,y_train_Complete,y_test_Complete=train_test_split(x_Complete,y_Complete,test_size=0.20,random_state=77,stratify=y_Complete)\n",
    "logger.info('Complete Splitted Successfully')\n",
    "x_test_Test,_,y_test_Test,_=train_test_split(x_Test,y_Test,test_size=0.20,random_state=77,stratify=y_Test)\n",
    "logger.info('Test Splitted Successfully')\n",
    "logger.info('======= End Of Data Split =======\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def modelTrainer(model, x_train, y_train, model_name, method_name):\n",
    "    logger.info(f\"Starting to train {method_name} model...\")\n",
    "    start = time.time()\n",
    "    model.fit(x_train,y_train)\n",
    "    end = time.time()\n",
    "    logger.info(f\"The {model_name} model trained in: {str(end - start)} seconds\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logistic Regression Models\n",
    "\n",
    "logger.info('======= Start Of Logistic Regression Model Generation =======')\n",
    "LogR_param_grid={'penalty':['l2'], 'C':[0.1,1,10,100], 'max_iter':[1024], 'solver': ['lbfgs'] } \n",
    "LogR_model_Durum=GridSearchCV(LogisticRegression(), LogR_param_grid, n_jobs=-1)\n",
    "LogR_model_Bread=GridSearchCV(LogisticRegression(), LogR_param_grid, n_jobs=-1)\n",
    "LogR_model_Complete=GridSearchCV(LogisticRegression(), LogR_param_grid, n_jobs=-1)\n",
    "\n",
    "modelTrainer(LogR_model_Durum, x_train_Durum, y_train_Durum, \"Durum\", \"LogR\")\n",
    "modelTrainer(LogR_model_Bread, x_train_Bread, y_train_Bread, \"Bread\", \"LogR\")\n",
    "modelTrainer(LogR_model_Complete, x_train_Complete, y_train_Complete, \"Complete\", \"LogR\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM Models\n",
    "\n",
    "logger.info('======= Start Of SVM Model Generation =======')\n",
    "SVM_param_grid={'C':[0.1,1,10,100],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf','poly']}\n",
    "svc=svm.SVC(probability=True)\n",
    "SVM_model_Durum=GridSearchCV(svm.SVC(probability=True), SVM_param_grid, n_jobs=-1)\n",
    "SVM_model_Bread=GridSearchCV(svm.SVC(probability=True), SVM_param_grid, n_jobs=-1)\n",
    "SVM_model_Complete=GridSearchCV(svm.SVC(probability=True), SVM_param_grid, n_jobs=-1)\n",
    "\n",
    "modelTrainer(SVM_model_Durum, x_train_Durum, y_train_Durum, \"Durum\", \"SVM\")\n",
    "modelTrainer(SVM_model_Bread, x_train_Bread, y_train_Bread, \"Bread\", \"SVM\")\n",
    "modelTrainer(SVM_model_Complete, x_train_Complete, y_train_Complete, \"Complete\", \"SVM\")\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# K Nearest Neighbors Models\n",
    "\n",
    "logger.info('======= Start Of K Nearest Neighbors Model Generation =======')\n",
    "KNN_param_grid={'n_neighbors':[5], 'weights':['uniform', 'distance']}\n",
    "KNN_model_Durum=GridSearchCV(KNeighborsClassifier(), KNN_param_grid, n_jobs=-1)\n",
    "KNN_model_Bread=GridSearchCV(KNeighborsClassifier(), KNN_param_grid, n_jobs=-1)\n",
    "KNN_model_Complete=GridSearchCV(KNeighborsClassifier(), KNN_param_grid, n_jobs=-1)\n",
    "\n",
    "modelTrainer(KNN_model_Durum, x_train_Durum, y_train_Durum, \"Durum\", \"KNN\")\n",
    "modelTrainer(KNN_model_Bread, x_train_Bread, y_train_Bread, \"Bread\", \"KNN\")\n",
    "modelTrainer(KNN_model_Complete, x_train_Complete, y_train_Complete, \"Complete\", \"KNN\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forest Models\n",
    "\n",
    "logger.info('======= Start Of Random Forest Model Generation =======')\n",
    "RanF_param_grid={'n_estimators':[100], 'criterion': ['gini', 'entropy']}\n",
    "RanF_model_Durum=GridSearchCV(RandomForestClassifier(), RanF_param_grid, n_jobs=-1)\n",
    "RanF_model_Bread=GridSearchCV(RandomForestClassifier(), RanF_param_grid, n_jobs=-1)\n",
    "RanF_model_Complete=GridSearchCV(RandomForestClassifier(), RanF_param_grid, n_jobs=-1)\n",
    "\n",
    "modelTrainer(RanF_model_Durum, x_train_Durum, y_train_Durum, \"Durum\", \"RanF\")\n",
    "modelTrainer(RanF_model_Bread, x_train_Bread, y_train_Bread, \"Bread\", \"RanF\")\n",
    "modelTrainer(RanF_model_Complete, x_train_Complete, y_train_Complete, \"Complete\", \"RanF\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generation of confusion matrix for all models\n",
    "\n",
    "Classification_Label = ['Logistic Regression', 'Support Vector Machine', 'K Nearest Neighbors', 'Random Forest']\n",
    "Classification_Model = [ [LogR_model_Durum, LogR_model_Bread, LogR_model_Complete], [SVM_model_Durum, SVM_model_Bread, SVM_model_Complete], [KNN_model_Durum, KNN_model_Bread, KNN_model_Complete], [RanF_model_Durum, RanF_model_Bread, RanF_model_Complete]]\n",
    "Train_Labels = ['Durum', 'Bread', 'Complete']\n",
    "Test_Data_Sets = [(x_test_Durum, y_test_Durum), (x_test_Bread, y_test_Bread), (x_test_Complete, y_test_Complete), (x_test_Test, y_test_Test)]\n",
    "Data_Set_Label = ['Durum', 'Bread', 'Complete', 'Test']\n",
    "\n",
    "\n",
    "classification_model = []\n",
    "train_data_used = []\n",
    "test_data_used = []\n",
    "false_positive_rate = [] # fp / (fp + tn)\n",
    "false_negative_rate = [] # fn / (tp + fn)\n",
    "true_negative_rate = [] # tn / (tn + fp)\n",
    "negative_predictive_value = [] # tn / (tn + fn)\n",
    "false_discovery_rate = [] # fp / (tp + fp)\n",
    "true_positive_rate = [] # tp / (tp + fn)\n",
    "precision = [] # tp / (tp + fp)\n",
    "accuracy = [] # (tp + tn) / (tp + fp + fn + tn) \n",
    "f1_score = [] \n",
    "f2_score = []\n",
    "\n",
    "fig_conf, axes_conf = plt.subplots(nrows=7, ncols=7, figsize=(35,30))\n",
    "fig_roc, axes_roc = plt.subplots(nrows=4, ncols=3, figsize=(35,30))\n",
    "axes_conf = axes_conf.flatten()\n",
    "axes_roc = axes_roc.flatten()\n",
    "i=0\n",
    "\n",
    "for C_Label, C_Models in zip(Classification_Label, Classification_Model):\n",
    "    for Model, T_Label in zip(C_Models, Train_Labels):\n",
    "        for Test_Set, Test_Data_Label in zip(Test_Data_Sets, Data_Set_Label):\n",
    "            \n",
    "            y_test_pred = Model.predict(Test_Set[0])\n",
    "            \n",
    "            # For confusion matrix\n",
    "            cf_matrix = confusion_matrix(Test_Set[1], y_test_pred)\n",
    "            ncf_matrix = cf_matrix.astype('float') / cf_matrix.sum(axis=1)[:, np.newaxis]            \n",
    "            disp_conf = ConfusionMatrixDisplay(ncf_matrix ,display_labels=['infected', 'healthy'])\n",
    "            disp_conf.plot(ax=axes_conf[i], xticks_rotation=45)\n",
    "            disp_conf.im_.colorbar.remove()\n",
    "            axes_conf[i].title.set_text(f\"{C_Label} Confusion Matrix ({T_Label}\\n Model x {Test_Data_Label} Data)\")\n",
    "\n",
    "            # For metrics table\n",
    "            tn, fp, fn, tp = cf_matrix.ravel()\n",
    "            classification_model.append(C_Label)\n",
    "            train_data_used.append(T_Label)\n",
    "            test_data_used.append(Test_Data_Label)\n",
    "            false_positive_rate.append(fp / (fp + tn))\n",
    "            false_negative_rate.append(fn / (tp + fn)) \n",
    "            true_negative_rate.append(tn / (tn + fp)) \n",
    "            negative_predictive_value.append(tn / (tn + fn))\n",
    "            false_discovery_rate.append(fp / (tp + fp))\n",
    "            true_positive_rate.append(tp / (tp + fn))\n",
    "            precision.append(tp / (tp + fp)) \n",
    "            accuracy.append((tp + tn) / (tp + fp + fn + tn))\n",
    "            f1_score.append(fbeta_score(Test_Set[1], y_test_pred, beta=1))\n",
    "            f2_score.append(fbeta_score(Test_Set[1], y_test_pred, beta=2))\n",
    "\n",
    "            # For auc_roc curve\n",
    "            fpr, tpr, thresholds = roc_curve(Test_Set[1], y_test_pred)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            disp_roc = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)  \n",
    "            disp_roc.plot(ax=axes_roc[i//4], label=f\"{Test_Data_Label} Data AUC = {roc_auc:.2f}\")\n",
    "            axes_roc[i//4].title.set_text(f\"{C_Label} ROC Curve ({T_Label}\\n Model)\")\n",
    "             \n",
    "            i = i + 1\n",
    "\n",
    "axes_conf[48].set_axis_off()\n",
    "fig_conf.tight_layout(pad=3.0)\n",
    "# fig_conf.savefig('confusion_matrix.png')\n",
    "\n",
    "fig_roc.tight_layout(pad=3.0)\n",
    "fig_roc.savefig('ROC_curve.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate metrics table\n",
    "metrics_df = pd.DataFrame(list(zip(classification_model,train_data_used,test_data_used,false_positive_rate,false_negative_rate,true_negative_rate,negative_predictive_value,false_discovery_rate,true_positive_rate,precision,accuracy,f1_score,f2_score)),\n",
    "               columns =['Classifier', 'Training Data', 'Test Data', 'False Positive Rate', 'False Negative Rate', 'True Negative Rate', 'Negative Predictive Value', 'False Discovery Rate', 'True Positive Rate', 'Precision', 'Accuracy', 'F1 Score', 'F2 Score'])\n",
    "\n",
    "\n",
    "metrics_df.to_csv('metrics_df.csv',index=False)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ba9ac630c9f2dd3511fdfeda2d56f08e3335139f33aea9e4eda54962c7821d0"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('thesis_env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}